{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForPreTraining, AutoTokenizer, AutoModelForPreTraining\n",
    "import torch\n",
    "from glob import glob\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertForPreTraining.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def chunks(xs, n):\n",
    "    \"\"\"Yield successive n-sized chunks from a list.\"\"\"\n",
    "    n = max(1, n)\n",
    "    return (xs[i:i+n] for i in range(0, len(xs), n))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "21"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_files = glob(\"lecture_texts/*.txt\")\n",
    "len(text_files)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for text_file_path in text_files:\n",
    "    with open(text_file_path, \"r\", encoding=\"utf\") as f:\n",
    "        text += f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# with open(\"lecture_texts/Matematička logika i računarstvo - Čačić - 1.12.2022. - 1. sat (192kbit_AAC)_hrv.txt\", \"r\", encoding=\"utf\") as f:\n",
    "#     text = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "sentences = text.split(\".\")\n",
    "sentences = list(map(lambda x: x.lstrip().rstrip(), sentences))\n",
    "bag = [sentence for sentence in sentences if sentence != \"\"]\n",
    "bag = [sentence+\".\" for sentence in bag]\n",
    "bag_size = len(bag)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "5911"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "592"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_size = 10\n",
    "paragraphs = list(chunks(bag, paragraph_size))\n",
    "len(paragraphs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label = []\n",
    "\n",
    "for sentences in paragraphs:\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 1:\n",
    "        start = random.randint(0, num_sentences-2)\n",
    "        # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "        if random.random() >= 0.5:\n",
    "            # this is IsNextSentence\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            label.append(0)\n",
    "        else:\n",
    "            index = random.randint(0, bag_size-1)\n",
    "            # this is NotNextSentence\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(bag[index])\n",
    "            label.append(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Imali smo niz formula A0, A1 itd.\n",
      "---\n",
      "Ima svojstvo konačnih presijeka, dakle, filtr generiran s njom je pravi.\n",
      "\n",
      "0\n",
      "Stvarno bih rekao da ovak na prvi pogled da sve štima i nalikuje na ovaj naš dokaz, jedino što ne ide sa nizom formula nego ide sa skupom formula, ali mislim da se vrlo jednostavno može svesti na ovo što smo mi radili, na obliku kojem smo mi radili, tako da mislim da će to biti jedna od zadataka za zadaću, dakle da pročitate taj dokaz na Math Overflowu i da ga zapišete u ovoj našoj notaciji kad smo već kod toga.\n",
      "---\n",
      "Dakle, prva zadaća će biti objavljena do kraja tjedna, dakle do Božića, onda ćete naravno ne samo preko Božićnih praznika, ali ono tamo negdje do kraja sječnja bi bilo lijepo da je riješite i pošaljete.\n",
      "\n",
      "1\n",
      "Naravno, kad god ih imam konačno mnogo, onda nema nekog, ne pada nam na pamet neki ljepši način da to napravimo, nego da jednostavno odaberemo jednog od njih i kažemo to je to.\n",
      "---\n",
      "Ali mislim da sam uspio, samo sad.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(label[i])\n",
    "    print(sentence_a[i] + '\\n---')\n",
    "    print(sentence_b[i] + '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda', index=0)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"tbs17/MathBERT\")\n",
    "model = AutoModelForPreTraining.from_pretrained(\"tbs17/MathBERT\")\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(torch.device(\"cuda\"))\n",
    "model.device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
    "inputs.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1],\n        [0],\n        [1],\n        [0],\n        [1]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['next_sentence_label'] = torch.LongTensor([label]).T\n",
    "inputs.next_sentence_label[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "inputs.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[14, 16, 32, 39, 42]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )\n",
    "selection[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'next_sentence_label', 'labels'])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103\n",
    "inputs.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "dataset = OurDataset(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/296 [00:00<?, ?it/s]C:\\Users\\mpajas.DESKTOP-0MU8OSB\\AppData\\Local\\Temp\\ipykernel_1364\\2644920816.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Epoch 0: 100%|██████████| 296/296 [01:09<00:00,  4.27it/s, loss=0.879]\n",
      "Epoch 1: 100%|██████████| 296/296 [01:04<00:00,  4.59it/s, loss=1.21] \n",
      "Epoch 2: 100%|██████████| 296/296 [01:04<00:00,  4.56it/s, loss=0.289]\n",
      "Epoch 3: 100%|██████████| 296/296 [01:05<00:00,  4.51it/s, loss=0.365]\n",
      "Epoch 4: 100%|██████████| 296/296 [01:05<00:00,  4.52it/s, loss=0.651]\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = model.device\n",
    "optim = Adam(model.parameters(), lr=1e-6, weight_decay=0.3)#, weight_decay=True)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(data_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        next_sentence_label = batch['next_sentence_label'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        next_sentence_label=next_sentence_label,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "('./MathBERT_hr\\\\tokenizer_config.json',\n './MathBERT_hr\\\\special_tokens_map.json',\n './MathBERT_hr\\\\vocab.txt',\n './MathBERT_hr\\\\added_tokens.json',\n './MathBERT_hr\\\\tokenizer.json')"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./MathBERT_hr\")\n",
    "tokenizer.save_pretrained(\"./MathBERT_hr\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
